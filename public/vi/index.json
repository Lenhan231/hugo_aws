[
{
	"uri": "http://localhost:1313/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Trọng Nhân\nSố điện thoại: SE190515\nEmail: nhanle221199@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nLớp: SE190525\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "http://localhost:1313/vi/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-09-09\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 1\u0026rdquo;\nLecture Notes What Is Cloud Computing? The on-demand delivery of IT resources over the Internet with pay-as-you-go pricing. Benefits of Cloud Computing Pay only for what you use, optimizing cost efficiency. Accelerate development through automation and managed services. Scale resources up or down as needed. Deploy applications globally in minutes. Why AWS? AWS has been the global cloud leader for 13 consecutive years (as of 2023). Unique culture, vision, and long-term customer obsession. AWS pricing philosophy: customers should pay less over time for the same resources. Every AWS Leadership Principle is focused on delivering real customer value. How to Get Started with AWS There are many learning paths—self-study is completely possible. Register an AWS Free Tier account to explore. Recommended course platforms: Udemy A Cloud Guru Explore AWS learning paths: AWS Learning Paths AWS Infrastructure Data Centers Each data center can host tens of thousands of servers. AWS builds and manages its own custom hardware for efficiency and reliability. Availability Zone (AZ) One or more physically separate data centers within a Region. Each AZ is designed for fault isolation. Connected via low-latency, high-throughput private links. AWS recommends deploying workloads across at least two AZs. Region A Region contains at least three Availability Zones. There are currently 25+ Regions worldwide. Regions are interconnected by the AWS backbone network. Most services are Region-scoped by default. Edge Locations Global network of edge sites designed to serve content with minimal latency. Used by services such as: Amazon CloudFront (CDN) AWS WAF (Web Application Firewall) Amazon Route 53 (DNS Service) AWS Management Tools AWS Management Console Log in as Root User or IAM User (requires 12-digit Account ID). Search and access individual service dashboards. Support Center allows you to open support cases directly. AWS Command Line Interface (CLI) Open-source command-line tool for interacting with AWS services. Provides functionality equivalent to the Console. AWS SDK (Software Development Kit) Simplifies integration of AWS services within applications. Handles authentication, retries, and data serialization/deserialization automatically. Cost Optimization on AWS Choose the right resource types and Regions. Use pricing models such as Reserved Instances, Savings Plans, and Spot Instances. Remove or schedule idle resources. Leverage serverless architectures. Continuously review and improve cost efficiency with AWS Budgets and Cost Explorer. Tag resources with Cost Allocation Tags for department-level tracking. AWS Pricing Calculator calculator.aws\nCreate and share cost estimates for common services. Pricing varies by Region. AWS Support Plans Four tiers: Basic, Developer, Business, and Enterprise. Plans can be upgraded temporarily during critical incidents. Exploration AWS Well-Architected Framework A set of design principles and best practices for building reliable, secure, efficient, and cost-effective cloud architectures. The Well-Architected Tool in the Console provides self-assessments and improvement guidance. Hands-On Labs Lab 01 – AWS Account \u0026amp; IAM Setup Create an AWS Account → 01-01 Configure Virtual MFA Device → 01-02 Create Admin Group and Admin User → 01-03 Account Authentication Support → 01-04 Lab 07 – AWS Budgets \u0026amp; Cost Management Create Budget by Template → 07-01 Create Cost Budget Tutorial → 07-02 Create Usage Budget → 07-03 Create Reserved Instance (RI) Budget → 07-04 Create Savings Plans Budget → 07-05 Clean Up Budgets → 07-06 Lab 09 – AWS Support Plans AWS Support Packages → 09-01 Types of Support Requests → 09-02 Change Support Package → 09-03 Manage Support Requests → 09-04 "
},
{
	"uri": "http://localhost:1313/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "KenFi – Nền tảng thương mại và thành viên thể hình AI Nền tảng AWS Serverless Stack thống nhất dành cho Thành viên, Thương mại điện tử và Huấn luyện Thể hình AI 1. Tóm tắt điều hành KenFi là nền tảng số hóa dành cho các phòng gym nội bộ hoặc chuỗi gym quy mô vừa và nhỏ tại Việt Nam, kết hợp ba chức năng chính trên một hệ thống duy nhất: bán gói tập trực tuyến, bán sản phẩm bổ trợ thể hình (whey, creatine, phụ kiện…), và hỗ trợ dinh dưỡng – AI tư vấn tập luyện.\nKhách hàng có thể đăng ký gói tập trực tuyến, thanh toán ngay bằng VNPay hoặc PayPal phiên bản thử, và nhận Mã Khách Hàng (Customer ID) hoặc QR Code để quét khi đến quầy lễ tân. Mọi thao tác đều thực hiện qua web – không cần cài ứng dụng riêng.\nVề phía vận hành, KenFi giúp chủ phòng gym tự động hóa khâu đăng ký – gia hạn – check-in, giảm tải công việc cho lễ tân, đồng thời chuẩn hóa danh tính khách hàng thông qua hệ thống mã hóa thống nhất trên nền tảng AWS.\nHệ thống được triển khai dựa trên kiến trúc serverless của AWS, đảm bảo chi phí vận hành cực thấp (ước tính chỉ ~0.7 USD/tháng, tương đương 8.40 USD cho 12 tháng) nhưng vẫn đủ khả năng mở rộng lên hàng nghìn hội viên nếu cần.\nKenFi không chỉ phục vụ việc quản lý hội viên, mà còn đóng vai trò nền tảng thương mại điện tử thu nhỏ dành riêng cho gym, đồng thời tích hợp công cụ tính dinh dưỡng theo bảng USDA và chatbot AI với phong cách “Bro thân thiện – nhưng nói chuyên môn thì nghiêm túc”.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nHầu hết các phòng tập thể dục địa phương ở Việt Nam vẫn phụ thuộc nhiều vào các quy trình thủ công. Tư cách thành viên thường được theo dõi trên giấy hoặc tệp Excel cơ bản. Khách hàng phải đến trực tiếp quầy để đăng ký hoặc gia hạn, gây chậm trễ, chen chúc trong giờ cao điểm. Không có tùy chọn tự phục vụ để mua tư cách thành viên hoặc thực phẩm bổ sung trực tuyến. Danh tính khách hàng không được chuẩn hóa—mỗi chi nhánh hoặc nhân viên có thể sử dụng các định dạng khác nhau, dẫn đến nhầm lẫn và hồ sơ không nhất quán. Ngoài ra, tư vấn dinh dưỡng và calo thường không chính thức, tùy thuộc vào bất kỳ huấn luyện viên nào có sẵn, dẫn đến lời khuyên không nhất quán.\nTrải nghiệm kỹ thuật số mong đợi mà khách hàng mong muốn:\nCác thành viên phòng tập thể dục hiện đại mong đợi mức độ tiện lợi tương tự mà họ nhận được từ thương mại điện tử hoặc ngân hàng trực tuyến. Họ muốn đăng ký gói đào tạo trực tiếp trên điện thoại, thanh toán ngay lập tức bằng các cổng thanh toán phổ biến như VNPay hoặc PayPal và nhận mã QR thành viên hoặc ID khách hàng ngay lập tức. Họ muốn được hướng dẫn rõ ràng về lượng calo nạp vào và sử dụng bổ sung mà không cần phải liên tục hỏi quầy lễ tân. Họ cũng mong muốn hệ thống nhận ra họ ngay lập tức khi nhận phòng mà không lặp lại thông tin cá nhân.\nKhoảng cách trên thị trường:\nTrong khi các chuỗi thể dục lớn ở Việt Nam như California Fitness hay CityGym có hệ thống kỹ thuật số một phần, không có nền tảng thống nhất, giá cả phải chăng để các phòng tập thể dục vừa và nhỏ hoạt động với cùng mức độ chuyên nghiệp. Mua các hệ thống làm sẵn từ các nhà cung cấp nước ngoài rất tốn kém và không được tối ưu hóa cho quy trình làm việc của Việt Nam. Hầu hết các sản phẩm phần mềm \u0026ldquo;quản lý phòng tập thể dục\u0026rdquo; hiện nay chỉ tập trung vào việc theo dõi điểm danh, không tích hợp thương mại điện tử, hướng dẫn dinh dưỡng hoặc hỗ trợ dựa trên AI.\nKenFi là giải pháp\nKenFi thu hẹp khoảng cách này bằng cách cung cấp nền tảng thành viên và thương mại thể dục do AWS cung cấp được thiết kế riêng cho các phòng tập thể dục địa phương. Nó tập trung đăng ký thành viên, thanh toán kỹ thuật số, bán thực phẩm bổ sung, tính toán dinh dưỡng và nhận dạng khách hàng vào một hệ sinh thái thân thiện duy nhất. Khách hàng nhận được ID khách hàng hoặc Mã QR duy nhất ngay sau khi mua gói hàng, có thể hiển thị cho nhân viên lễ tân để nhận biết ngay lập tức. Chatbot AI tích hợp hoạt động như một người anh em phòng tập thể dục thân thiện cho các câu hỏi thông thường, nhưng chuyển sang chế độ chuyên gia nghiêm túc khi thảo luận về các chủ đề kỹ thuật thể dục. Nền tảng này cho phép các phòng tập thể dục nhỏ hoạt động với sự chuyên nghiệp của các chuỗi thể dục lớn mà không yêu cầu cơ sở hạ tầng hoặc bảo trì trả trước nặng nề.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nNền tảng KenFi sẽ được triển khai trong các giai đoạn được xác định rõ ràng để đảm bảo tạo mẫu nhanh chóng trong khi vẫn duy trì khả năng mở rộng lâu dài.\nGiai đoạn 1 – Lập kế hoạch kiến trúc và thiết lập dịch vụ AWS. Xác định chính xác các tài nguyên AWS cần thiết bao gồm Amplify, Cognito User Pool, API Gateway, hàm Lambda, bảng DynamoDB và vùng lưu trữ S3. Thiết lập quy ước đặt tên, lựa chọn khu vực và vai trò IAM.\nGiai đoạn 2 – Quy trình làm việc thành viên cốt lõi. Triển khai quy trình đăng ký tài khoản, mua gói đào tạo, tạo ID khách hàng và mã QR cũng như lưu trữ hiệu lực thành viên trong DynamoDB.\nGiai đoạn 3 – Bổ sung mô-đun thương mại. Xây dựng danh mục sản phẩm, quy trình thêm vào giỏ hàng, thanh toán qua VNPay hoặc PayPal sandbox và theo dõi lịch sử đơn hàng.\nGiai đoạn 4 – Tích hợp máy tính dinh dưỡng. Kết nối các hàm Lambda với API Trung tâm FoodData của USDA, cho phép người dùng nhập các mặt hàng thực phẩm và nhận phân tích calo và vĩ mô.\nGiai đoạn 5 – Chatbot AI. Tích hợp mô hình LLM nhẹ chạy trên Lambda hoặc tùy chọn thông qua Amazon Bedrock. Định cấu hình chuyển đổi hành vi giữa chế độ \u0026ldquo;anh em phòng tập thể dục\u0026rdquo; thông thường và chế độ chuyên gia nghiêm túc. Dịch vụ AWS và trách nhiệm chính\nAWS Amplify lưu trữ giao diện người dùng Next.js và tự động hóa CI/CD từ GitHub hoặc CodeCommit.\nAmazon Cognito quản lý đăng ký, đăng nhập, đặt lại mật khẩu và mã thông báo danh tính.\nAmazon API Gateway hiển thị các điểm cuối HTTPS bảo mật cho tất cả các hành động của ứng dụng.\nCác hàm AWS Lambda xử lý logic kinh doanh như mua thành viên, tạo mã QR và tra cứu dinh dưỡng.\nAmazon DynamoDB lưu trữ hồ sơ khách hàng, mã thông báo thành viên, hồ sơ giao dịch và hàng tồn kho sản phẩm.\nAmazon S3 lưu trữ các tài sản công khai như hình ảnh QR, hình ảnh biểu ngữ và thẻ thành viên có thể tải xuống.\nBạn có thể sử dụng Amazon SES tùy chọn để gửi email xác nhận có tệp đính kèm mã QR.\nQuy trình tạo mã QR\nKhi giao dịch mua được xác nhận, Lambda sẽ tạo một chuỗi thành viên duy nhất bằng cách sử dụng tiền tố như KF-YYYYMM-XXXX. Mã QR được hiển thị thông qua thư viện tạo QR, được lưu trữ tạm thời trong bộ nhớ và được lưu dưới dạng tệp hình ảnh trong S3 theo đường dẫn như /qr-codes/customer-id.png. URL được trả về giao diện người dùng và tùy chọn gửi qua email cho khách hàng.\nKết nối cổng thanh toán\nTài khoản VNPay và PayPal sandbox được sử dụng trong quá trình phát triển. Giao diện người dùng chuyển hướng người dùng đến URL thanh toán thích hợp. Sau khi hoàn tất, VNPay hoặc PayPal trả về callback đến API Gateway với trạng thái giao dịch. Một hàm Lambda chuyên dụng xác minh chữ ký thanh toán và đánh dấu tư cách thành viên là đang hoạt động.\nChiến lược triển khai\nToàn bộ cơ sở hạ tầng có thể được cung cấp thủ công thông qua Bảng điều khiển AWS trong giai đoạn nguyên mẫu. Sau khi ổn định, cơ sở hạ tầng dưới dạng mã sẽ được áp dụng bằng AWS CDK hoặc CloudFormation để triển khai có thể tái tạo trên các môi trường. Phiên bản cho Lambda và chiến lược khôi phục sẽ được thực thi.\nKiểm tra và kiểm soát chất lượng\nKiểm thử đơn vị được thực hiện trên từng hàm Lambda một cách độc lập. Tích hợp giao diện người dùng được xác minh thông qua các bản dựng xem trước Amplify. Thử nghiệm toàn diện từ đầu đến cuối được mô phỏng với một người dùng giả đăng ký, mua, nhận mã QR và đăng ký. Kiểm tra thâm nhập tập trung vào kiểm soát truy cập và ngăn chặn giả mạo thanh toán.\n5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 Phòng.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-09-16\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 2\u0026rdquo;\nLecture Notes Networking Services on AWS Amazon Virtual Private Cloud (VPC) Amazon Virtual Private Cloud (Amazon VPC) allows you to launch AWS resources into a virtual network you define. A VPC exists within a single Region. When creating a VPC, you must define an IPv4 CIDR block (required) and optionally an IPv6 one. The default limit is 5 VPCs per Region per Account. Commonly used to separate environments such as Production, Development, and Staging. To achieve full resource isolation, use separate AWS Accounts rather than multiple VPCs. Subnets A subnet resides within one Availability Zone. The subnet CIDR must be a subset of the parent VPC’s CIDR block. AWS reserves 5 IP addresses in each subnet: network, broadcast, router, DNS, and future use. A route table defines how traffic is directed. Each VPC has a default route table containing only a local route allowing internal communication between subnets. Custom route tables can be created, but the local route cannot be deleted. Elastic Network Interface (ENI) An ENI is a virtual network card that can be moved between EC2 instances. It retains its private IP, Elastic IP address, and MAC address when reassigned. Elastic IP (EIP) is a static public IPv4 address that can be associated with an ENI. Unused EIPs incur charges. A VPC Endpoint enables private connectivity to supported AWS services via AWS PrivateLink without using the public Internet. Two types: Interface Endpoint: Uses an ENI with a private IP. Gateway Endpoint: Uses route tables (available for S3 and DynamoDB only). Internet Gateway (IGW) A horizontally scalable, redundant, and highly available VPC component that allows communication between instances in your VPC and the Internet. Fully managed by AWS – no manual scaling or HA configuration required. NAT Gateway Allows instances in private subnets to access the Internet or other AWS services, but prevents inbound Internet connections. Security Group (SG) A stateful virtual firewall that controls inbound and outbound traffic to AWS resources. Rules are based on protocol, port, source, or another security group. Only allow rules are supported. Applied to Elastic Network Interfaces (ENIs). Network Access Control List (NACL) A stateless virtual firewall that operates at the subnet level. Rules control inbound and outbound traffic by protocol, port, and source. Default NACL allows all traffic. VPC Flow Logs Capture metadata about IP traffic to and from network interfaces in your VPC. Logs can be delivered to Amazon CloudWatch Logs or S3. Flow Logs do not record packet payloads. VPC Peering \u0026amp; Transit Gateway VPC Peering Enables direct, private connectivity between two VPCs without traversing the Internet. Does not support transitive routing or overlapping CIDRs. AWS Transit Gateway (TGW) Acts as a hub to connect multiple VPCs and on-prem networks, simplifying complex mesh topologies. TGW Attachments associate subnets in specific AZs with a TGW. All subnets within the same AZ can reach the TGW once attached. VPN \u0026amp; Direct Connect Site-to-Site VPN Establishes a secure IPSec connection between an on-premises data center and AWS VPC. Consists of: Virtual Private Gateway (VGW): AWS-managed, multi-AZ endpoints. Customer Gateway (CGW): Customer-managed device or software appliance. AWS Direct Connect Provides a dedicated private network connection between an on-prem data center and AWS. Typical latency: 20–30 ms. In Vietnam, available through Hosted Connections (via partners). Bandwidth is adjustable. Elastic Load Balancing (ELB) Overview A fully managed service distributing traffic across multiple targets (EC2, containers, etc.). Supports HTTP, HTTPS, TCP, TLS. Can be deployed in public or private subnets. Provides DNS names; only NLB supports static IPs. Includes health checks and access logs (to S3). Supports sticky sessions (session affinity). Types: Application, Network, Classic, and Gateway Load Balancer. Application Load Balancer (ALB) Operates at Layer 7 (HTTP/HTTPS). Supports path-based routing (e.g., /mobile vs /desktop). Targets: EC2, Lambda, IP addresses, containers (ECS/EKS). Network Load Balancer (NLB) Operates at Layer 4 (TCP/TLS). Supports static IPs and handles millions of requests per second. Targets: EC2, IP addresses, containers (ECS/EKS). Gateway Load Balancer (GWLB) Operates at Layer 3 (IP packets). Uses the GENEVE protocol on port 6081. Routes traffic to virtual appliances such as firewalls or monitoring tools. Partner list: aws.amazon.com/elasticloadbalancing/partners Typical GWLB architecture:\nExploration AWS Advanced Networking – Specialty Study Guide Official study guide covering exam topics, AWS network design principles, and real-world architecture scenarios. Hands-On Labs Lab 03 – Amazon VPC \u0026amp; Networking Basics Create VPC → 03-03.1 Create Subnet → 03-03.2 Create Internet Gateway (IGW) → 03-03.3 Create Route Table (Outbound via IGW) → 03-03.4 Create Security Groups → 03-03.5 Launch EC2 Instances in Subnets → 04-1 Test Connection Between Instances → 04-2 Create NAT Gateway (Private ↔ Internet) → 04-3 EC2 Instance Connect Endpoint (no bastion) → 04-5 Lab 10 – Hybrid DNS (Route 53 Resolver) Generate Key Pair → 10-02.1 Initialize CloudFormation Template → 10-02.2 Configure Security Group → 10-02.3 Set up DNS System → 10-05 Create Route 53 Outbound Endpoint → 10-05.1 Create Resolver Rules → 10-05.2 Create Inbound Endpoints → 10-05.3 Lab 19 – VPC Peering Initialize CloudFormation Templates → 19-02.1 Create Security Group → 19-02.2 Create EC2 Instance (Test Peering) → 19-02.3 Create Peering Connection → 19-04 Configure Route Tables (Cross-VPC) → 19-05 Enable Cross-Peer DNS → 19-06 Lab 20 – AWS Transit Gateway Preparation Steps → 20-02 Create Transit Gateway → 20-03 Create TGW Attachments → 20-04 Create TGW Route Tables → 20-05 Add TGW Routes to VPC Route Tables → 20-06 "
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-09-30\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 3\u0026rdquo;\nLecture Notes Compute on AWS Amazon Elastic Compute Cloud (EC2) Amazon EC2 provides resizable compute capacity in the cloud, similar to a virtual or physical server. It supports workloads such as web hosting, applications, databases, authentication services, and other general-purpose server tasks. Instance Types\nEC2 configurations are defined by instance types, not custom hardware. Each type specifies: CPU (Intel, AMD, ARM – Graviton 1/2/3) / GPU Memory Network Storage Amazon Machine Images (AMI) AMI (Amazon Machine Image) is a template that defines the software configuration of an instance, including OS, apps, and settings. Types of AMIs: Provided by AWS (Amazon Linux, Windows, Ubuntu, etc.) AWS Marketplace AMIs Custom AMIs created by users Benefits of Custom AMIs\nFaster instance launch and setup Simplified backup and restore Consistent environment across multiple instances Backup in EC2 AWS Backup provides centralized backup for AWS services including EC2. EBS Snapshots back up EBS volumes: Point-in-time backups Incremental (stores only changed blocks) Stored in S3 (not directly accessible) AMI Backup captures the full EC2 configuration as an image. Key Pair Key Pairs are used for secure authentication when connecting to EC2: Public Key – stored on the instance Private Key – kept by the user for SSH (Linux) or RDP (Windows) Replaces passwords for better security. Important: If you lose your private key, AWS cannot recover it. Elastic Block Store (EBS) Amazon EBS provides persistent block storage for EC2 instances. Volume types: General Purpose SSD (gp2/gp3) – balance between performance \u0026amp; cost Provisioned IOPS SSD (io1/io2) – for high IOPS workloads Throughput Optimized HDD (st1) – for large, sequential data Cold HDD (sc1) – low-cost, infrequently accessed data Key Features\nAttach/detach volumes from instances Data persists when instances stop Create snapshots for backup or cross-region copy Automatically replicated within an AZ Instance Store Instance Store provides temporary block-level storage physically attached to the EC2 host. Characteristics\nVery high I/O and throughput Data lost when instance stops or terminates Cannot be detached or snapshotted Use Cases\nCaching or temporary data processing Applications with their own redundancy or replication User Data User Data scripts run automatically at instance launch (once per AMI provision). Linux – bash scripts Windows – PowerShell scripts Metadata EC2 Instance Metadata provides details about the running instance such as private/public IP, hostname, and security groups. Often used in user data scripts for dynamic configuration. Amazon EC2 Auto Scaling EC2 Auto Scaling automatically adjusts the number of EC2 instances based on demand. Benefits\nElastic capacity adjustment Increased application availability Cost optimization Components\nAuto Scaling Group (ASG) – logical group of EC2 instances Launch Template / Configuration – defines instance parameters Scaling Policies – rules for adding/removing instances Scaling Policies Simple / Step Scaling – add/remove instances when thresholds are met Target Tracking – maintain a metric (e.g., CPU = 50%) Scheduled Scaling – scale on a predefined schedule Predictive Scaling – uses ML to forecast and scale proactively Integration with Load Balancer ASGs often pair with Elastic Load Balancers (ELB). New instances automatically register; terminated instances deregister automatically. EC2 Pricing Options On-Demand: Pay per hour/second. Most expensive but flexible. Reserved Instances: 1- or 3-year commitment for discount; tied to specific instance type/family. Savings Plans: 1- or 3-year commitment; flexible across instance families. Spot Instances: Use spare capacity at up to 90% discount; can be terminated with 2-minute notice. Combine multiple pricing models within an Auto Scaling Group for cost optimization.\nAmazon Lightsail Simplified compute service with predictable monthly pricing (starting ~$3.5/month). Includes bundled data transfer at lower rates than EC2. Ideal for small workloads, development, or testing environments. Supports snapshots for backups. Runs inside a managed VPC and can connect to standard VPCs via one-click peering. Amazon EFS (Elastic File System) Fully managed NFSv4 file system mountable by multiple EC2 instances simultaneously. Scales automatically to petabytes. Pay only for the storage used (unlike EBS provisioned size). Can be mounted from on-prem via VPN or Direct Connect. Amazon FSx Managed, scalable file systems for Windows, Lustre, and NetApp ONTAP. AWS handles setup, scaling, and backups. Accessible from EC2, on-prem servers, or users via SMB or NFS protocols. AWS Application Migration Service (MGN) Used for migrating or replicating physical/virtual servers to AWS for DR or modernization. Continuously replicates source machines to lightweight staging instances on EC2. During cut-over, MGN launches fully functional EC2 instances from the replicated data. Exploration Microsoft Workloads on AWS A curated series covering deployment, optimization, and best practices for running Microsoft workloads on AWS. Hands-On Labs Lab 01 – AWS Account \u0026amp; IAM Setup Create AWS Account → 01-01 Setup Virtual MFA Device → 01-02 Create Admin Group and Admin User → 01-03 Account Authentication Support → 01-04 Lab 07 – AWS Budgets \u0026amp; Cost Management Create Budget by Template → 07-01 Create Cost Budget Tutorial → 07-02 Create Usage Budget → 07-03 Create Reserved Instance Budget → 07-04 Create Savings Plans Budget → 07-05 Clean Up Budgets → 07-06 Lab 09 – AWS Support Plans AWS Support Packages → 09-01 Types of Support Requests → 09-02 Change Support Package → 09-03 Manage Support Requests → 09-04 "
},
{
	"uri": "http://localhost:1313/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-09-30\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 4\u0026rdquo;\nLecture Notes Storage Services on AWS Amazon Simple Storage Service (S3) Amazon S3 is an object storage service designed to store and retrieve any amount of data from anywhere on the web. It offers virtually unlimited scalability, high availability, strong security, and excellent performance.\nCore S3 Features Buckets and Objects: Data is stored as objects inside buckets. Each object can be up to 5 TB. Availability and Durability: S3 is designed for 99.99% availability and 99.999999999% (11 nines) durability. Security: Multiple layers of security including IAM, bucket policies, ACLs, and encryption. Scalability: Automatically scales storage and request throughput without performance degradation. S3 Access Points Access Points simplify managing data access for shared datasets in S3.\nPer-application access control: Each access point has its own policy. Operational simplicity: Eases permission management for shared datasets used by many applications. Network controls: Can be configured to accept requests only from specific VPCs. S3 Storage Classes Choose among storage classes optimized for different access patterns and cost profiles:\nS3 Standard: For frequently accessed data; highest availability and performance. S3 Intelligent-Tiering: Automatically moves objects between tiers to optimize cost. S3 Standard-IA (Infrequent Access): Lower cost for infrequently accessed data with millisecond retrieval. S3 One Zone-IA: Like Standard-IA but stored in a single AZ. S3 Glacier Flexible Retrieval: Low-cost archival with minutes-to-hours retrieval. S3 Glacier Deep Archive: Lowest-cost archival with ~12-hour retrieval. Amazon S3 Static Website Hosting Host static websites (HTML, CSS, JS, images) directly from S3.\nKey Capabilities Simple setup: A few steps to enable static website hosting on a bucket. Low cost: Pay standard S3 storage and data transfer; no separate web server charges. Elastic scaling: Automatically handles traffic spikes. CDN integration: Easily front with Amazon CloudFront for global performance. Cross-Origin Resource Sharing (CORS) CORS allows web resources (fonts, JavaScript, etc.) on one domain to request resources from another domain.\nConfiguring CORS on S3 Define policies: Specify which origins are permitted to access a bucket’s content. Control methods: Allow specific HTTP methods (GET, PUT, POST, etc.). Security posture: Prevent unauthorized cross-origin access. Performance and Object Key Design Object key naming can significantly affect S3 performance:\nRandomized prefixes: Distribute keys across partitions for higher parallelism. Avoid sequential prefixes: Don’t use monotonically increasing prefixes (e.g., timestamps) for high-throughput workloads. Parallel access: Structure keys to enable concurrent reads/writes. S3 Glacier – Long-Term Archival S3 Glacier classes are optimized for ultra–low-cost long-term storage.\nRetrieval Options Expedited / Fast: Minutes; highest cost. Standard: 3–5 hours; balanced cost. Bulk: 5–12 hours; lowest cost for large restores. Glacier Deep Archive The lowest-cost class for multi-year retention, with ~12-hour retrieval times.\nAWS Snow Family Purpose-built devices and services to move large datasets into and out of AWS when networks are limited or data volumes are massive.\nAWS Snowcone: Small, rugged device (~8 TB). Suited for edge and remote sites. AWS Snowball: Snowball Edge Storage Optimized: Up to ~80 TB usable storage. Snowball Edge Compute Optimized: Adds powerful compute with ~42 TB storage. AWS Snowmobile: Exabyte-scale data transfer (up to 100 PB) in a secure containerized data center. AWS Storage Gateway Hybrid cloud storage service that connects on-premises applications with cloud-backed storage.\nGateway Types File Gateway\nNFS/SMB file shares backed by S3 objects. Use cases: user shares, application backups, archives. Volume Gateway\niSCSI block storage backed by S3 with EBS snapshots. Modes: Cached volumes: Primary data in S3; local cache on-prem. Stored volumes: Primary data on-prem; async copy to S3. Use cases: on-prem block workloads with cloud backup/DR. Tape Gateway\nVirtual Tape Library (VTL) for existing backup apps (e.g., NetBackup, Veeam). Writes appear as tape but land in S3/Glacier. Use cases: tape replacement and archival modernization. Disaster Recovery (DR) on AWS Disaster Recovery is about restoring IT services after major incidents (outages, disasters, hardware failures, cyberattacks).\nRTO (Recovery Time Objective): How quickly to restore service. RPO (Recovery Point Objective): How much data loss (time window) is acceptable. DR Strategies (ordered by complexity \u0026amp; cost) Backup \u0026amp; Restore\nMaintain backups only (EBS/RDS snapshots, S3/Glacier). Restore to new infrastructure during incidents. RTO: hours–days. RPO: depends on backup frequency. Cost: lowest. Pilot Light\nMinimal core services always running on AWS. Scale out to full production during DR. RTO: hours. RPO: minutes. Cost: moderate. Warm Standby\nFull system running at reduced scale on AWS. Scale up on failover. RTO: minutes–hours. RPO: seconds–minutes. Cost: higher. Multi-Site (Active/Active or Active/Passive)\nProduction running across on-prem and AWS, or multi-Region AWS. Traffic can be shifted instantly (Route 53, Global Accelerator). RTO/RPO: near zero. Cost: highest. AWS Backup Centralized backup service for automating and governing data protection at scale.\nKey Capabilities Central management: Define and apply backup policies across services. Multi-service support: EC2, EBS, RDS, DynamoDB, EFS, Storage Gateway, S3, and more. Scheduling \u0026amp; lifecycle: Automate backups and retention. Compliance: Support for governance and audit requirements. Benefits Operational simplicity: No custom scripts or disparate tools. Time savings: Automated, policy-driven protection. Reporting \u0026amp; audit: Visibility into backup status and compliance. Backup Vault Lock Immutability controls to prevent modifications or deletions of protected backups for strict compliance. Exploration AWS Skill Builder Curated learning plans and deep-dive content for storage specialists: Storage Learning Plan: Block Storage Storage Learning Plan: Object Storage Hands-On Labs Lab 13 – AWS Backup Create S3 Bucket → 13-02.1 Deploy Infrastructure → 13-02.2 Create Backup Plan → 13-03 Set Up Notifications → 13-04 Test Restore → 13-05 Clean Up Resources → 13-06 Lab 14 – AWS VM Import/Export VMware Workstation → 14-01 Export Virtual Machine from On-Premises → 14-02.1 Upload Virtual Machine to AWS → 14-02.2 Import Virtual Machine to AWS → 14-02.3 Deploy Instance from AMI → 14-02.4 Set Up S3 Bucket ACL → 14-03.1 Export Virtual Machine from Instance → 14-03.2 Resource Cleanup on AWS → 14-05 Lab 24 – AWS Storage Gateway (On-Premises Integration) Create Storage Gateway → 24-2.1 Create File Shares → 24-2.2 Mount File Shares On-Prem → 24-2.3 Clean Up Resources → 24-3 Lab 25 – Amazon FSx (File Systems) Create SSD Multi-AZ File System → 25-2.2 Create HDD Multi-AZ File System → 25-2.3 Create New File Shares → 25-3 Test Performance → 25-4 Monitor Performance → 25-5 Enable Data Deduplication → 25-6 Enable Shadow Copies → 25-7 Manage User Sessions and Open Files → 25-8 Enable User Storage Quotas → 25-9 Scale Throughput Capacity → 25-11 Scale Storage Capacity → 25-12 Delete Environment → 25-13 Lab 57 – Amazon S3 \u0026amp; CloudFront Create S3 Bucket → 57-2.1 Load Data → 57-2.2 Enable Static Website → 57-3 Configure Public Access Block → 57-4 Configure Public Objects → 57-5 Test Website → 57-6 Block All Public Access → 57-7.1 Configure CloudFront → 57-7.2 Test CloudFront → 57-7.3 Bucket Versioning → 57-8 Move Objects → 57-9 Replicate Objects Across Regions → 57-10 Clean Up Resources → 57-11 "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-10-07\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 5\u0026rdquo;\nLecture Notes Security Shared Responsibility Model In cloud computing, security is a shared responsibility between the cloud provider and the customer. Customers must securely configure services, apply best practices, and use security controls from the hypervisor exposure upward to application/data layers. The split of responsibilities varies by service model: Infrastructure-level services Partially managed services Fully managed services AWS Identity and Access Management (IAM) Root Account Has unrestricted access to all AWS services/resources and can remove any attached permissions. Best practices: Create and use an IAM Administrator user for daily operations. Lock away root credentials (dual control). Keep the root user’s email and domain valid and renewed. IAM Overview IAM controls access to AWS services and resources in your account. Principals include: root user, IAM users, federated users, IAM roles, assumed-role sessions, AWS services, and anonymous users. Notes: IAM users are not separate AWS accounts. New IAM users start with no permissions. Grant permissions by attaching policies to users, groups, or roles. Use IAM groups to manage many users (groups cannot be nested). IAM Policies JSON documents defining permissions. Types: Identity-based policies (attached to principals) Resource-based policies (attached to resources) Evaluation rule: explicit Deny overrides Allow across all policies. Pattern to constrain S3 administration:\nAllow all s3:* actions on a specific bucket. Explicitly Deny all non-S3 actions. IAM Roles Roles provide temporary permissions assumed by users, services, or external identities. Common use cases: Let an AWS service act on your behalf (e.g., EC2 → S3 writes) Cross-account access Federation from external IdPs Credentials for apps on EC2 without storing access keys Benefits\nNo long-term credentials, short-lived sessions, least privilege, and easier large-scale access management. Amazon Cognito Managed authentication/authorization and user management for web \u0026amp; mobile apps. Components: User Pools: Sign-up/sign-in user directories. Identity Pools: Federated identities for temporary AWS credentials to access services. AWS Organizations Centrally manage multiple AWS accounts in a single organization. Benefits\nCentralized account management Consolidated Billing Hierarchies with Organizational Units (OUs) Guardrails with Service Control Policies (SCPs) Organizational Units (OUs) Group accounts by department, project, or environment; nest OUs for hierarchical policies. Consolidated Billing One invoice for all accounts; volume pricing benefits; no extra cost. Service Control Policies (SCPs) Define maximum permissions for accounts; they limit but do not grant permissions. Apply to accounts or OUs; affect all users/roles, including root; Deny overrides Allow. Example SCP (deny bucket deletion)\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:DeleteBucket\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } AWS Identity Center (formerly AWS SSO) Centralizes access to AWS accounts and external applications. Identity sources: built-in, AWS Managed Microsoft AD, on-prem AD (trust/AD Connector), or external IdPs. Permission Sets define what users/groups can do in target accounts (materialized as IAM roles). Multiple permission sets per user are supported. AWS Key Management Service (KMS) Managed keys for data protection with deep service integration and full auditability. Highlights\nCreate/manage keys without operating your own HSM infrastructure. Fine-grained access via IAM \u0026amp; key policies; usage logged in CloudTrail. Key categories\nCustomer-managed keys, AWS-managed keys, and AWS-owned keys. AWS Security Hub Aggregates and prioritizes security findings and posture across accounts/services. Capabilities\nAutomated checks, normalized findings, prioritized remediation workflows. Compliance standards: CIS AWS Foundations, PCI DSS, AWS Foundational Security Best Practices. Integrations\nGuardDuty, Inspector, Macie, Firewall Manager, IAM Access Analyzer, plus partner tools. Outcomes\nLess time aggregating, more time fixing; unified visibility and improved security hygiene. Exploration AWS Certified Security – Specialty: All-in-One Exam Guide (SCS-C01) Comprehensive preparation material for the Security Specialty certification. Hands-On Labs Lab 18 – AWS Security Hub Enable Security Hub → 18-02 Score for Each Set of Criteria → 18-03 Clean Up Resources → 18-04 Lab 22 – AWS Lambda Automation with Slack Create VPC → 22-2.1 Create Security Group → 22-2.2 Create EC2 Instance → 22-2.3 Incoming Webhooks (Slack) → 22-2.4 Create Tag for Instance → 22-3 Create Role for Lambda → 22-4 Function: Stop Instance → 22-5.1 Function: Start Instance → 22-5.2 Check Result → 22-6 Clean Up Resources → 22-7 Lab 27 – AWS Resource Groups \u0026amp; Tagging Create EC2 Instance with Tag → 27-2.1.1 Manage Tags in AWS Resources → 27-2.1.2 Filter Resources by Tag → 27-2.1.3 Use Tags with CLI → 27-2.2 Create a Resource Group → 27-3 Clean Up Resources → 27-4 Lab 28 – IAM Cross-Region Role \u0026amp; Policy Create IAM User → 28-2.1 Create IAM Policy → 28-3 Create IAM Role → 28-4 Switch Roles → 28-5.1 Access EC2 Console – Tokyo → 28-5.2.1 Access EC2 Console – N. Virginia → 28-5.2.2 Create EC2 (No Qualified Tags) → 28-5.2.3 Edit EC2 Resource Tag → 28-5.2.4 Policy Check → 28-5.2.5 Clean Up Resources → 28-6 Lab 30 – IAM Restriction Policy Create Restriction Policy → 30-3 Create IAM Limited User → 30-4 Test IAM User Limits → 30-5 Clean Up Resources → 30-6 Lab 33 – AWS KMS \u0026amp; CloudTrail Integration Create Policy and Role → 33-2.1 Create Group and User → 33-2.2 Create KMS Key → 33-3 Create S3 Bucket → 33-4.1 Upload Data to S3 → 33-4.2 Create CloudTrail → 33-5.1 Log to CloudTrail → 33-5.2 Create Amazon Athena → 33-5.3 Query with Athena → 33-5.4 Test \u0026amp; Share Encrypted S3 Data → 33-6 Resource Cleanup → 33-7 Lab 44 – IAM Advanced Role Control Create IAM Group → 44-2 Create IAM Users → 44-3.1 Check Permissions → 44-3.2 Create Admin IAM Role → 44-4.1 Configure Switch Role → 44-4.2 Restrict Switch Role by IP → 44-4.3.1 Restrict Switch Role by Time → 44-4.3.2 Clean Up Resources → 44-5 Lab 48 – IAM Access Keys \u0026amp; Roles Create EC2 Instance → 48-1.1 Create S3 Bucket → 48-1.2 Generate IAM User and Access Key → 48-2.1 Use Access Key → 48-2.2 Create IAM Role → 48-3.1 Use IAM Role → 48-3.2 Clean Up Resources → 48-4 "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "http://localhost:1313/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Date: 2025-10-07\nStatus: \u0026ldquo;Done\u0026rdquo;\nWeek: \u0026ldquo;Week 6\u0026rdquo;\nLecture Notes Database Concepts Review A database is an organized (or semi-structured) collection of information stored on storage devices to support concurrent access by multiple users or programs with different goals. Sessions A session spans from the moment a client connects to the DBMS until the connection is terminated. Primary Key A primary key uniquely identifies each row in a relational table. Foreign Key A foreign key in one table references the primary key of another table, creating a relationship between them. Index An index accelerates data retrieval at the cost of extra writes and storage to maintain the index structure. Indexes locate data without scanning every row; they can be defined over one or more columns. Partitioning Partitioning splits a large table into smaller, independent pieces (partitions), potentially placed on different storage. Benefits: better query performance, easier maintenance, and scalability. Common types: Range (e.g., by date) List Hash Composite (combination) Execution Plan / Query Plan A query plan details how the DBMS will execute an SQL statement (access paths, joins, sorts). Types: Estimated plan (before execution) Actual plan (from executed query) Key operators: table scan, index seek/scan, nested loops, hash/merge join, sort, aggregate, filter. Database Logs Database logs record all changes (INSERT/UPDATE/DELETE) and operations. Typical log types: transaction, redo, undo, binary logs. Uses: recovery, integrity, consistency/durability (ACID), replication, performance analysis. Buffers A buffer pool caches pages read from disk to minimize I/O. Management strategies: Replacement: LRU, FIFO, Clock Write policies: immediate vs. deferred Prefetching to warm the cache RDBMS An RDBMS stores data in related tables (rows/columns), enforces integrity constraints, uses SQL, and provides ACID guarantees. Popular engines: Oracle, MySQL, SQL Server, PostgreSQL, IBM Db2. NoSQL Overview NoSQL systems target un/semistructured data with high scalability and performance. Types: Document (MongoDB, CouchDB) Key–Value (Redis, DynamoDB) Column-Family (Cassandra, HBase) Graph (Neo4j, Amazon Neptune) Traits: schema flexibility, horizontal scaling, big-data friendliness, CAP-oriented designs. RDBMS vs. NoSQL (high-level) OLTP vs. OLAP OLTP: many small, concurrent transactions; normalized data; short queries; index-heavy. OLAP: complex analytics over large historical datasets; star/snowflake schemas; read-heavy. Amazon RDS \u0026amp; Aurora Amazon Relational Database Service (RDS) Managed relational databases that simplify provisioning, patching, backups, and HA.\nSupported engines: MySQL, PostgreSQL, MariaDB, Oracle, SQL Server, Amazon Aurora. Key features: automated backups/patching, easy scaling, Multi-AZ high availability, encryption \u0026amp; VPC/IAM/SSL security. Deployment options: Single-AZ Multi-AZ (synchronous standby in another AZ) Read Replicas for scaling reads Amazon Aurora Cloud-native, MySQL/PostgreSQL-compatible relational database re-architected for AWS.\nHighlights: Up to ~5× MySQL / ~3× PostgreSQL performance (typical benchmarks) Storage auto-scales to 128 TB Six-way replication across three AZs; self-healing storage Aurora Serverless (on-demand capacity) Global Database for low-latency multi-region Amazon Redshift Fully managed cloud data warehouse optimized for large-scale analytics (OLAP).\nColumnar storage, compression, MPP execution; scales from hundreds of GB to PB. Integrations: S3, Kinesis, DynamoDB, BI tools; strong security features. Concurrency Scaling adds capacity automatically during spikes. Architecture: cluster (leader node + compute nodes), each compute node has slices. Deployment options:\nRedshift Provisioned Redshift Serverless Redshift Spectrum (query S3 directly) Use cases: enterprise BI, data lake analytics, dashboards, trend analysis, forecasting.\nAmazon ElastiCache Managed in-memory caching service for Redis and Memcached to reduce latency and offload databases.\nMicrosecond reads, Multi-AZ with failover, simple scaling, encryption/auth, automated ops. Redis: rich data structures, backups, replication, cluster mode. Memcached: simple, horizontally scalable cache with auto-discovery. Common uses: web/mobile acceleration, DB query caching, session stores, leaderboards, pub/sub, queues.\nExploration The Data Warehouse Toolkit Canonical reference for dimensional modeling and DW design patterns. Hands-On Labs Lab 05 – Amazon RDS \u0026amp; EC2 Integration Create a VPC → 05-2.1 Create EC2 Security Group → 05-2.2 Create RDS Security Group → 05-2.3 Create DB Subnet Group → 05-2.4 Create EC2 Instance → 05-3 Create RDS Database Instance → 05-4 Application Deployment → 05-5 Backup and Restore → 05-6 Clean Up Resources → 05-7 Lab 43 – AWS Database Migration Service (DMS) EC2 Connect RDP Client → 43-01 EC2 Connect Fleet Manager → 43-02 SQL Server Source Config → 43-03 Oracle Connect Source DB → 43-04 Oracle Config Source DB → 43-05 Drop Constraint → 43-06 MSSQL → Aurora MySQL Target Config → 43-07 MSSQL → Aurora MySQL Create Project → 43-08 MSSQL → Aurora MySQL Schema Conversion → 43-09 Oracle → MySQL Schema Conversion (1) → 43-10 Create Migration Task \u0026amp; Endpoints → 43-11 Inspect S3 → 43-12 Create Serverless Migration → 43-13 Create Event Notification → 43-14 Logs → 43-15 Troubleshoot: Memory Pressure → 43-16 Troubleshoot: Table Error → 43-17 "
},
{
	"uri": "http://localhost:1313/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/vi/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Module 1 Date: September 9, 2025\nStatus: Done\nWeek: Week 1\n"
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.1-blog1/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Tăng tốc luồng dữ liệu và AI của bạn bằng cách kết nối đến Amazon SageMaker Unified Studio từ Visual Studio Code bởi Lauren Mullennex, Anagha Barve, Anchit Gupta, và Bhargava Varadharajan vào ngày 12 THÁNG 9 2025 trong Amazon SageMaker AI, Amazon SageMaker Unified Studio, Announcements, Intermediate (200), Technical How-to\nCác nhà phát triển và kỹ sư học máy (ML) giờ đây có thể kết nối trực tiếp tới Amazon SageMaker Unified Studio từ trình soạn thảo Visual Studio Code (VS Code) cục bộ của họ. Với khả năng này, bạn có thể giữ nguyên quy trình phát triển hiện có và cấu hình môi trường phát triển tích hợp (IDE) cá nhân hóa, đồng thời truy cập các dịch vụ phân tích AWS và trí tuệ nhân tạo \u0026amp; máy học (AI/ML) trong một môi trường phát triển dữ liệu và AI hợp nhất. Sự tích hợp này cung cấp truy cập liền mạch từ môi trường phát triển cục bộ của bạn đến cơ sở hạ tầng có thể mở rộng để chạy xử lý dữ liệu, phân tích SQL và các luồng công việc ML. Bằng cách kết nối IDE cục bộ của bạn với SageMaker Unified Studio, bạn có thể tối ưu hóa luồng phát triển dữ liệu và AI mà không làm gián đoạn các thực tiễn phát triển đã thiết lập.\nTrong bài viết này, chúng tôi minh họa cách kết nối VS Code cục bộ của bạn đến SageMaker Unified Studio để bạn có thể xây dựng luồng công việc dữ liệu và AI đầu-cuối trong khi làm việc trong môi trường phát triển ưa thích của bạn.\nTổng quan giải pháp Kiến trúc giải pháp bao gồm ba thành phần chính:\nMáy tính cục bộ – Máy phát triển của bạn chạy VS Code với AWS Toolkit cho Visual Studio Code và Microsoft Remote SSH được cài đặt. Bạn có thể kết nối thông qua extension Toolkit cho VS Code bằng cách duyệt các không gian (spaces) SageMaker Unified Studio có sẵn và chọn môi trường mục tiêu của chúng.\nSageMaker Unified Studio – Là phần của thế hệ kế tiếp của Amazon SageMaker, SageMaker Unified Studio là một môi trường phát triển dữ liệu và AI duy nhất, nơi bạn có thể tìm và truy cập dữ liệu của mình và thao tác nó bằng các công cụ AWS quen thuộc cho phân tích SQL, xử lý dữ liệu, phát triển mô hình và phát triển ứng dụng AI tạo sinh.\nAWS Systems Manager – Một dịch vụ truy cập từ xa và quản lý an toàn, có khả năng mở rộng, giúp kết nối liền mạch giữa VS Code cục bộ của bạn và các không gian SageMaker Unified Studio để đơn giản hóa luồng phát triển dữ liệu và AI.\nSơ đồ sau đây biểu diễn sự tương tác giữa IDE cục bộ của bạn và các không gian SageMaker Unified Studio.\nCác điều kiện tiên quyết Để thử kết nối IDE từ xa, bạn phải có các điều kiện sau:\nTruy cập vào domain SageMaker Unified Studio có kết nối Internet. Với các domain được cấu hình ở chế độ chỉ VPC, domain của bạn phải có tuyến ra Internet qua proxy hoặc NAT gateway. Nếu domain của bạn hoàn toàn cô lập khỏi Internet, tham khảo tài liệu để thiết lập kết nối từ xa. Nếu bạn chưa có domain SageMaker Unified Studio, bạn có thể tạo một domain bằng tùy chọn thiết lập nhanh (quick setup) hoặc thiết lập thủ công (manual setup).\nMột người dùng với thông tin đăng nhập SSO thông qua IAM Identity Center được yêu cầu. Để cấu hình truy cập người dùng SSO, hãy xem tài liệu.\nTruy cập hoặc có thể tạo một dự án SageMaker Unified Studio.\nCompute Space JupyterLab hoặc Code Editor với yêu cầu loại instance tối thiểu 8 GB bộ nhớ. Trong bài viết này, chúng tôi dùng instance ml.t3.large. Phiên bản ảnh phân phối SageMaker Distribution image phiên bản 2.8 trở lên được hỗ trợ.\nBạn có VS Code bản ổn định mới nhất với Microsoft Remote SSH (phiên bản 0.74.0 trở lên) và extension AWS Toolkit (phiên bản 3.74.0) được cài đặt trên máy cục bộ của bạn.\nTriển khai giải pháp Để cho phép kết nối từ xa và kết nối tới không gian từ VS Code, hoàn tất các bước sau. Để kết nối tới một space SageMaker Unified Studio từ xa, space đó phải được bật tính năng truy cập từ xa.\nĐiều hướng tới space JupyterLab hoặc Code Editor của bạn. Nếu nó đang chạy, dừng space và chọn Configure space để bật truy cập từ xa\nBật Remote access để kích hoạt tính năng và chọn Save and restart.\nĐiều hướng tới AWS Toolkit trong cài đặt VS Code cục bộ của bạn.\nTrên tab SageMaker Unified Studio, chọn Sign in để bắt đầu và cung cấp URL domain SageMaker Unified Studio, ví dụ https://\u0026lt;domain‑id\u0026gt;.sagemaker.\u0026lt;region\u0026gt;.on.aws.\nBạn sẽ được yêu cầu chuyển hướng sang trình duyệt web để cho phép truy cập các extension IDE AWS. Chọn Open để mở tab trình duyệt mới.\nChọn Allow access để kết nối tới dự án qua VS Code.\nBạn sẽ nhận được thông báo Request approved, cho thấy bạn đã có quyền truy cập domain từ xa.\nQuay lại VS Code cục bộ của bạn để truy cập dự án và tiếp tục xây dựng các công việc ETL, pipeline dữ liệu, đào tạo \u0026amp; triển khai mô hình ML hoặc xây ứng dụng AI tạo sinh. Để kết nối tới dự án cho xử lý dữ liệu và phát triển ML, thực hiện các bước:\nChọn Select a project để xem dữ liệu và tài nguyên tính toán. Tất cả các dự án trong domain được liệt kê, nhưng bạn chỉ được phép truy cập các dự án mà bạn là thành viên.\nBạn chỉ có thể xem một domain và một dự án tại một thời điểm. Để chuyển dự án hoặc đăng xuất khỏi domain, chọn biểu tượng dấu ba chấm.Bạn cũng có thể xem tài nguyên dữ liệu và tính toán mà bạn đã tạo trước đó.\nKết nối space JupyterLab hoặc Code Editor bằng cách chọn biểu tượng kết nối. Nếu tùy chọn này không hiển thị, có thể bạn đã tắt truy cập từ xa trong space. Nếu space đang ở trạng thái “Stopped”, di chuột lên space và chọn nút connect, điều này sẽ bật truy cập từ xa, khởi động space và kết nối nó. Nếu space đang ở trạng thái “Running”, space phải được khởi động lại với truy cập từ xa được bật bằng cách dừng space rồi kết nối lại từ toolkit.\nMột cửa sổ VS Code khác sẽ mở ra và được kết nối tới space SageMaker Unified Studio của bạn qua remote SSH.\nĐiều hướng tới Explorer để xem notebook, file và script của space. Từ AWS Toolkit, bạn cũng có thể xem nguồn dữ liệu của bạn.\nSử dụng thiết lập VS Code tùy chỉnh với tài nguyên SageMaker Unified Studio Khi bạn kết nối VS Code với SageMaker Unified Studio, bạn giữ nguyên tất cả phím tắt cá nhân và tùy chỉnh của bạn. Ví dụ, nếu bạn dùng đoạn code snippet để nhanh chóng chèn các mẫu mã phân tích và ML phổ biến, chúng vẫn hoạt động với cơ sở hạ tầng được quản lý của SageMaker Unified Studio.\nTrong hình minh họa, chúng tôi thể hiện cách sử dụng các snippet luồng phân tích: snippet “show-databases” truy vấn Athena để hiển thị các database có sẵn, “show-glue-tables” liệt kê bảng trong AWS Glue Data Catalog, và “query-ecommerce” lấy dữ liệu sử dụng Spark SQL để phân tích.\nBạn cũng có thể dùng các snippet để tự động hóa việc build và training mô hình ML trên SageMaker AI. Trong hình bên dưới, các snippet mã thể hiện xử lý dữ liệu, cấu hình và khởi chạy job đào tạo SageMaker AI. Cách tiếp cận này cho thấy người làm dữ liệu có thể giữ thiết lập phát triển quen thuộc của mình trong khi sử dụng tài nguyên dữ liệu và AI được quản lý trong SageMaker Unified Studio.\nVô hiệu hóa truy cập từ xa trong SageMaker Unified Studio Như một quản trị viên, nếu bạn muốn vô hiệu hóa tính năng này cho người dùng, bạn có thể thực thi nó bằng cách thêm chính sách sau vào vai trò IAM của dự án:\n{\n\u0026ldquo;Version\u0026rdquo;: \u0026ldquo;2012-10-17\u0026rdquo;,\n\u0026ldquo;Statement\u0026rdquo;: [\n{\n\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;DenyStartSessionForSpaces\u0026rdquo;,\n\u0026ldquo;Effect\u0026rdquo;: \u0026ldquo;Deny\u0026rdquo;,\n\u0026ldquo;Action\u0026rdquo;: [\n\u0026ldquo;sagemaker:StartSession\u0026rdquo;\n],\n\u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;arn:aws:sagemaker:*:*:space/*/*\u0026rdquo;\n}\n]\n}\nDọn dẹp Theo mặc định, SageMaker Unified Studio tắt các tài nguyên nhàn rỗi như các space JupyterLab và Code Editor sau 1 giờ. Nếu bạn đã tạo một domain SageMaker Unified Studio cho mục đích bài viết này, nhớ xóa domain đó.\nKết luận Kết nối trực tiếp từ IDE cục bộ của bạn đến Amazon SageMaker Unified Studio giảm ma sát khi chuyển giữa phát triển cục bộ và hạ tầng dữ liệu \u0026amp; AI có thể mở rộng. Bằng cách giữ cấu hình IDE cá nhân hóa, điều này giảm sự cần thiết phải thích nghi giữa các môi trường phát triển khác nhau. Dù bạn đang xử lý các tập dữ liệu lớn, đào tạo mô hình nền tảng (foundation models, FMs), hoặc xây dựng ứng dụng AI tạo sinh, bạn giờ có thể làm việc từ thiết lập cục bộ của mình trong khi truy cập các khả năng của SageMaker Unified Studio. Bắt đầu ngay hôm nay bằng cách kết nối IDE cục bộ của bạn đến SageMaker Unified Studio để hợp lý hóa luồng xử lý dữ liệu và tăng tốc phát triển mô hình ML.\nGiới thiệu về các tác giả Lauren Mullennex Lauren là Kiến trúc sư Giải pháp Chuyên gia về GenAI/ML Cấp cao tại AWS.\nCô có hơn một thập kỷ kinh nghiệm trong lĩnh vực học máy, DevOps và hạ tầng.\nCô là tác giả đã xuất bản một cuốn sách về thị giác máy tính.\nNgoài công việc, bạn có thể thấy cô đi du lịch và đi bộ đường dài cùng hai chú chó của mình.\nBhargava Varadharajan Bhargava là Kỹ sư Phần mềm Cấp cao tại Amazon Web Services, nơi anh phát triển các sản phẩm AI \u0026amp; ML như SageMaker Studio, Studio Lab và Unified Studio.\nTrong hơn năm năm qua, anh đã tập trung vào việc biến các quy trình AI \u0026amp; ML phức tạp thành trải nghiệm liền mạch.\nKhi không thiết kế các hệ thống quy mô lớn, Bhargava theo đuổi mục tiêu khám phá toàn bộ 63 công viên quốc gia Hoa Kỳ và tìm kiếm những cuộc phiêu lưu qua leo núi, bóng đá và trượt tuyết.\nThời gian rảnh của anh được chia cho các dự án DIY (tự làm) và nuôi dưỡng sự tò mò thông qua sách.\nAnagha Barve Anagha là Quản lý Phát triển Phần mềm trong nhóm Amazon SageMaker Unified Studio.\nAnchit Gupta Anchit là Quản lý Sản phẩm Cấp cao cho Amazon SageMaker Unified Studio.\nCô tập trung vào việc phát triển các sản phẩm giúp việc xây dựng giải pháp học máy trở nên dễ dàng hơn.\nVào thời gian rảnh, cô thích nấu ăn, chơi các trò chơi trên bàn/cờ, và đọc sách.\n"
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.2-blog2/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Thông báo Amazon EC2 M4 và M4 Pro Mac instances bởi Sébastien Stormacq vào ngày 12 THÁNG 9 2025 trong Amazon EC2 Mac Instances, Launch, News Permalink Comments\nPermalink Comments Share\nVoiced by Polly\nLà người đã sử dụng macOS từ năm 2001 và các Amazon EC2 Mac instances từ khi chúng ra mắt 4 năm trước, tôi đã giúp nhiều khách hàng mở rộng các pipeline tích hợp \u0026amp; phân phối liên tục (CI/CD) trên AWS. Hôm nay, tôi rất hào hứng chia sẻ rằng các instance Amazon EC2 M4 và M4 Pro Mac hiện đã khả dụng chính thức.\nCác nhóm phát triển xây ứng dụng cho các nền tảng Apple cần tài nguyên tính toán mạnh để xử lý các quy trình build phức tạp và chạy nhiều giả lập iOS cùng lúc. Khi các dự án phát triển ngày càng lớn và tinh vi, các nhóm cần hiệu năng và dung lượng bộ nhớ cao hơn để duy trì chu kỳ phát triển nhanh.\nApple M4 Mac mini làm lõi Các instance EC2 M4 Mac (được gọi là mac-m4.metal trong API) được xây dựng dựa trên máy Apple M4 Mac mini và sử dụng hệ thống AWS Nitro System. Chúng có chip Apple silicon M4 với 10 lõi CPU (bốn lõi hiệu năng và sáu lõi hiệu quả), GPU 10 lõi, Neural Engine 16 lõi, và bộ nhớ hợp nhất 24 GB, mang lại hiệu năng cải thiện cho các workload build ứng dụng iOS và macOS. Khi xây dựng và kiểm thử ứng dụng, các instance M4 Mac cho hiệu năng build ứng dụng tốt hơn tới 20% so với các instance EC2 M2 Mac.\nInstance EC2 M4 Pro Mac ( mac-m4pro.metal trong API ) được trang bị chip Apple silicon M4 Pro với 14 lõi CPU, 20 lõi GPU, Neural Engine 16 lõi và bộ nhớ hợp nhất 48 GB. Những instance này cung cấp hiệu năng build ứng dụng tốt hơn tới 15% so với các instance EC2 M2 Pro Mac. Thêm dung lượng bộ nhớ và công suất tính toán cho phép chạy nhiều bài kiểm thử song song bằng nhiều giả lập thiết bị.\nMỗi instance M4 và M4 Pro Mac giờ đây đi kèm với 2 TB lưu trữ nội bộ (local storage), cung cấp lưu trữ độ trễ thấp để cải thiện caching và hiệu năng build \u0026amp; test.\nCả hai loại instance đều hỗ trợ macOS Sonoma phiên bản 15.6 và mới hơn như các AMI (Amazon Machine Images (AMIs).). Hệ thống AWS Nitro cung cấp băng thông mạng Amazon Virtual Private Cloud (Amazon VPC) lên đến 10 Gbps và băng thông lưu trữ Amazon Elastic Block Store (Amazon EBS) 8 Gbps qua kết nối Thunderbolt tốc độ cao.\nCác instance EC2 Mac tích hợp liền mạch với các dịch vụ AWS, nghĩa là bạn có thể:\nXây dựng pipeline CI/CD tự động sử dụng AWS CodeBuild và AWS CodePipeline\nLưu trữ và quản lý nhiều phiên bản bí mật build của bạn, như chứng chỉ phát triển Apple và khóa, trên AWS Secrets Manager\nQuản lý hạ tầng phát triển của bạn bằng AWS CloudFormation\nGiám sát hiệu năng instance với Amazon CloudWatch\nCách bắt đầu Bạn có thể khởi chạy một instance EC2 M4 hoặc M4 Pro Mac qua AWS Management Console, AWS Command Line Interface (AWS CLI), or AWS SDKs.\nVí dụ trong demo này, tôi sẽ khởi động một instance M4 Pro từ console. Tôi đầu tiên cấp phát một dedicated host để chạy các instance của mình. Trên AWS Management Console tôi vào EC2, rồi Dedicated Hosts, và chọn Allocate Dedicated Host.\nRồi, tôi nhập tag Name và chọn Family instance (mac‑m4pro) và loại instance (mac‑m4pro.metal). Tôi chọn một Availability Zone và bỏ chọn Host maintenance.\nEC2 Mac M$ – Dedicated hosts\nHoặc tôi có thể dùng CLI:\naws ec2 allocate-hosts \\\n--availability-zone-id \u0026ldquo;usw2-az4\u0026rdquo; \\\n--auto-placement \u0026ldquo;off\u0026rdquo; \\\n--host-recovery \u0026ldquo;off\u0026rdquo; \\\n--host-maintenance \u0026ldquo;off\u0026rdquo; \\\n--quantity 1 \\\n--instance-type \u0026ldquo;mac-m4pro.metal\u0026rdquo;\nSau khi host dedicated được cấp cho tài khoản của tôi, tôi chọn host vừa cấp, rồi chọn menu Actions và chọn Launch instance(s) onto host.\nLưu ý console cung cấp cho bạn, bên cạnh các thông tin khác, các phiên bản macOS hỗ trợ mới nhất cho loại host này. Trong trường hợp này, là macOS 15.6.\nTrên trang Launch an instance, tôi nhập Name. Tôi chọn một AMI macOS Sequoia. Tôi đảm bảo Architecture là Arm 64-bit và loại instance là mac-m4pro.metal.\nPhần còn lại các tham số không đặc thù cho EC2 Mac: cấu hình mạng và lưu trữ. Khi khởi động một instance dùng cho phát triển, hãy chắc chọn volume tối thiểu 200 GB trở lên. Volume mặc định 100 GB không đủ để tải xuống và cài Xcode.\nKhi đã sẵn sàng, tôi nhấn nút Launch instance màu cam ở cuối trang. Instance sẽ nhanh chóng xuất hiện ở trạng thái Running trong console. Tuy nhiên, có thể mất tới 15 phút để bạn có thể kết nối qua SSH.\nHoặc tôi có thể dùng lệnh này:\naws ec2 run-instances \\\n--image-id \u0026ldquo;ami-000420887c24e4ac8\u0026rdquo; \\ # ID AMI tùy vùng !\n--instance-type \u0026ldquo;mac-m4pro.metal\u0026rdquo; \\\n--key-name \u0026ldquo;my-ssh-key-name\u0026rdquo; \\\n--network-interfaces \u0026lsquo;{\u0026ldquo;AssociatePublicIpAddress\u0026rdquo;:true,\u0026ldquo;DeviceIndex\u0026rdquo;:0,\u0026ldquo;Groups\u0026rdquo;:[\u0026ldquo;sg-0c2f1a3e01b84f3a3\u0026rdquo;]}\u0026rsquo; \\ # Security Group ID phụ thuộc config của bạn \\\n--tag-specifications \u0026lsquo;{\u0026ldquo;ResourceType\u0026rdquo;:\u0026ldquo;instance\u0026rdquo;,\u0026ldquo;Tags\u0026rdquo;:[{\u0026ldquo;Key\u0026rdquo;:\u0026ldquo;Name\u0026rdquo;,\u0026ldquo;Value\u0026rdquo;:\u0026ldquo;My Dev Server\u0026rdquo;}]}\u0026rsquo; \\\n--placement \u0026lsquo;{\u0026ldquo;HostId\u0026rdquo;:\u0026ldquo;h-0e984064522b4b60b\u0026rdquo;,\u0026ldquo;Tenancy\u0026rdquo;:\u0026ldquo;host\u0026rdquo;}\u0026rsquo; \\ # Host ID tùy config của bạn --private-dns-name-options \u0026lsquo;{\u0026ldquo;HostnameType\u0026rdquo;:\u0026ldquo;ip-name\u0026rdquo;,\u0026ldquo;EnableResourceNameDnsARecord\u0026rdquo;:true,\u0026ldquo;EnableResourceNameDnsAAAARecord\u0026rdquo;:false}\u0026rsquo; \\\n--count \u0026ldquo;1\u0026rdquo;\nCài Xcode từ Terminal Sau khi instance có thể truy cập, tôi có thể kết nối bằng SSH và cài công cụ phát triển. Tôi dùng xcodeinstall để tải và cài Xcode 16.4.\nTừ laptop của tôi, tôi mở session với credentials Apple developer:\n# on my laptop, with permissions to access AWS Secret Manager\n» xcodeinstall authenticate -s eu-central-1\nRetrieving Apple Developer Portal credentials\u0026hellip;\nAuthenticating\u0026hellip;\n🔐 Two factors authentication is enabled, enter your 2FA code: 067785\n✅ Authenticated with MFA.\nTôi kết nối với EC2 Mac instance cái mà tôi vừa mới launched. Sau đó, tôi tải và cài đặc Xcode:\n» ssh ec2-user@44.234.115.119\nWarning: Permanently added \u0026lsquo;44.234.115.119\u0026rsquo; (ED25519) to the list of known hosts.\nLast login: Sat Aug 23 13:49:55 2025 from 81.49.207.77\n┌───┬──┐ \\_\\_| \\_\\_|\\_ ) │ ╷╭╯╷ │ \\_| ( / │ └╮ │ \\_\\_\\_|\\\\\\_\\_\\_|\\_\\_\\_| │ ╰─┼╯ │ Amazon EC2 └───┴──┘ macOS Sequoia 15.6 ec2-user@ip-172-31-54-74 ~ % brew tap sebsto/macos\n==\u0026gt; Tapping sebsto/macos\nCloning into \u0026lsquo;/opt/homebrew/Library/Taps/sebsto/homebrew-macos\u0026rsquo;\u0026hellip;\nremote: Enumerating objects: 227, done.\nremote: Counting objects: 100% (71/71), done.\nremote: Compressing objects: 100% (57/57), done.\nremote: Total 227 (delta 22), reused 63 (delta 14), pack-reused 156 (from 1)\nReceiving objects: 100% (227/227), 37.93 KiB | 7.59 MiB/s, done.\nResolving deltas: 100% (72/72), done.\nTapped 1 formula (13 files, 61KB).\nec2-user@ip-172-31-54-74 ~ % brew install xcodeinstall\n==\u0026gt; Fetching downloads for: xcodeinstall\n==\u0026gt; Fetching sebsto/macos/xcodeinstall\n==\u0026gt; Downloading https://github.com/sebsto/xcodeinstall/releases/download/v0.12.0/xcodeinstall-0.12.0.arm64_sequoia.bottle.tar.gz\nAlready downloaded: /Users/ec2-user/Library/Caches/Homebrew/downloads/9f68a7a50ccfdc479c33074716fd654b8528be0ec2430c87bc2b2fa0c36abb2d\u0026ndash;xcodeinstall-0.12.0.arm64_sequoia.bottle.tar.gz\n==\u0026gt; Installing xcodeinstall from sebsto/macos\n==\u0026gt; Pouring xcodeinstall-0.12.0.arm64_sequoia.bottle.tar.gz\n🍺 /opt/homebrew/Cellar/xcodeinstall/0.12.0: 8 files, 55.2MB\n==\u0026gt; Running `brew cleanup xcodeinstall`\u0026hellip;\nDisable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\nHide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n==\u0026gt; No outdated dependents to upgrade!\nec2-user@ip-172-31-54-74 ~ % xcodeinstall download -s eu-central-1 -f -n \u0026ldquo;Xcode 16.4.xip\u0026rdquo;\nDownloading Xcode 16.4\n100% [============================================================] 2895 MB / 180.59 MBs\n[ OK ]\n✅ Xcode 16.4.xip downloaded\nec2-user@ip-172-31-54-74 ~ % xcodeinstall install -n \u0026ldquo;Xcode 16.4.xip\u0026rdquo;\nInstalling\u0026hellip;\n[1/6] Expanding Xcode xip (this might take a while)\n[2/6] Moving Xcode to /Applications\n[3/6] Installing additional packages\u0026hellip; XcodeSystemResources.pkg\n[4/6] Installing additional packages\u0026hellip; CoreTypes.pkg\n[5/6] Installing additional packages\u0026hellip; MobileDevice.pkg\n[6/6] Installing additional packages\u0026hellip; MobileDeviceDevelopment.pkg\n[ OK ]\n✅ file:///Users/ec2-user/.xcodeinstall/download/Xcode%2016.4.xip installed\nec2-user@ip-172-31-54-74 ~ % sudo xcodebuild -license accept\nec2-user@ip-172-31-54-74 ~ %\nNhững điều cần biết Chọn volume EBS tối thiểu 200 GB cho mục đích phát triển. Volume mặc định 100 GB không đủ để cài Xcode. Tôi thường chọn 500 GB. Khi tăng kích thước EBS sau khi instance đã khởi chạy, nhớ to resize the APFS filesystem.\nNgoài ra, bạn có thể chọn cài công cụ phát triển và framework của bạn lên ổ SSD nội bộ 2 TB độ trễ thấp có sẵn trong Mac mini. Lưu ý rằng nội dung volume này gắn với vòng đời instance, không với dedicated host. Nghĩa là mọi thứ sẽ bị xóa khỏi ổ SSD nội bộ khi bạn dừng và khởi động lại instance.\nCác instance mac-m4.metal và mac-m4pro.metal hỗ trợ macOS Sequoia 15.6 và các phiên bản mới hơn.\nBạn có thể di chuyển các instance EC2 Mac hiện tại khi instance di chuyển đang chạy macOS 15 (Sequoia). Tạo một AMI tùy chỉnh từ instance hiện tại và khởi động một instance M4 hoặc M4 Pro từ AMI đó.\nCuối cùng, tôi gợi ý bạn xem các hướng dẫn tôi viết để giúp bạn bắt đầu với EC2 Mac:\nKhởi động một instance EC2 Mac\nKết nối tới instance EC2 Mac (tôi chỉ bạn ba cách khác nhau để kết nối)\nXây ứng dụng nhanh hơn với pipeline CI/CD trên EC2 Mac\nGiá cả và khả dụng Các instance EC2 M4 và M4 Pro Mac hiện có tại US East (N. Virginia) và US West (Oregon), dự kiến mở rộng sang các vùng khác trong tương lai.\nCác instance EC2 Mac có thể mua dưới dạng Dedicated Hosts theo mô hình giá On-Demand và Savings Plans. Việc tính phí cho EC2 Mac là theo giây với mức tối thiểu 24 giờ cấp phát để tuân theo Thỏa thuận Bản quyền phần mềm macOS của Apple. Sau khoảng thời gian tối thiểu 24 giờ, host có thể được giải phóng bất cứ lúc nào mà không cần cam kết tiếp.\nLà người làm việc chặt với các nhà phát triển Apple, tôi tò mò xem bạn sẽ dùng các instance mới này như thế nào để tăng tốc chu kỳ phát triển của bạn. Sự kết hợp giữa hiệu năng gia tăng, dung lượng bộ nhớ cải thiện và tích hợp với dịch vụ AWS mở ra nhiều khả năng mới cho các đội xây ứng dụng cho iOS, macOS, iPadOS, tvOS, watchOS, và visionOS. Ngoài phát triển ứng dụng, Neural Engine của Apple silicon khiến các instance này là ứng viên hiệu quả chi phí để chạy workload inference machine learning (ML). Tôi sẽ thảo luận chi tiết chủ đề này tại AWS re:Invent 2025, nơi tôi sẽ chia sẻ benchmark và best practices để tối ưu workload ML trên EC2 Mac.\nĐể tìm hiểu thêm về các instance EC2 M4 và M4 Pro Mac, bạn có thể truy cập trang Amazon EC2 Mac Instances hoặc tham khảo EC2 Mac documentation. Bạn có thể bắt đầu sử dụng các instance này ngay hôm nay để hiện đại hóa workflow phát triển Apple trên AWS.\n— seb\nSébastien Stormacq\nSeb đã viết code từ khi chạm Commodore 64 giữa những năm tám mươi. Anh truyền cảm hứng cho những người xây dựng để khai phá giá trị của đám mây AWS, dùng hỗn hợp bí mật giữa đam mê, nhiệt huyết, advocacy khách hàng, tò mò và sáng tạo. Anh ta quan tâm đến kiến trúc phần mềm, công cụ dev và điện toán di động. Nếu bạn muốn bán cho anh cái gì đó, đảm bảo nó có API. Theo dõi @sebsto trên Bluesky, X, Mastodon và các nền tảng khác.\n"
},
{
	"uri": "http://localhost:1313/vi/3-blogstranslated/3.3-blog3/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Hướng dẫn tinh chỉnh cho Amazon EC2 instances dùng AMD bởi Suyash Nadkarni và Dylan Souvage vào ngày 12 THÁNG 9 2025 trong Amazon EC2, Best Practices, Expert (400), Technical\nKhi các tổ chức di chuyển nhiều khối lượng công việc quan trọng sang đám mây, tối ưu hóa về giá — hiệu suất (price-performance) trở thành một cân nhắc chủ chốt. Các instance Amazon Elastic Compute Cloud(Amazon EC2) sử dụng bộ xử lý AMD EPYC đem lại mật độ lõi cao, băng thông bộ nhớ lớn và các tính năng bảo mật được hỗ trợ phần cứng, khiến chúng trở thành một lựa chọn mạnh mẽ cho nhiều loại khối lượng công việc tính toán, bộ nhớ hoặc I/O. Trong bài viết này, chúng tôi giải thích cách chọn loại instance Amazon EC2 dựa trên AMD phù hợp và mô tả các kỹ thuật điều chỉnh có thể giúp người dùng cải thiện hiệu quả khối lượng công việc. Cho dù bạn đang chạy mô phỏng, phân tích quy mô lớn hoặc các khối lượng inference, bài viết này cung cấp hướng dẫn thực tiễn để tối ưu hóa instance Amazon EC2 dùng AMD.\nAmazon EC2 cung cấp instances AMD dựa trên nhiều thế hệ AMD EPYC. Bài viết tập trung vào chiến lược tối ưu cho thế hệ 3 và 4, vốn tăng cường khả năng cho workload tính toán và bộ nhớ chuyên sâu.\nThế hệ 3 (M6a, R6a, C6a, Hpc6a): Cân bằng tính toán, bộ nhớ và lưu trữ — phù hợp với phân tích dữ liệu, máy chủ web và tính toán hiệu năng cao.\nThế hệ thứ 4 (M7a, R7a, C7a, Hpc7a): Cung cấp hiệu suất tốt hơn tới 50% so với các thế hệ AMD trước đó. Các instance này giới thiệu hỗ trợ AVX‑512, bộ nhớ DDR5 và Simultaneous Multithreading (SMT) bị tắt; SMT là công nghệ cho phép một lõi vật lý chạy nhiều luồng cùng lúc; với SMT bị tắt, mỗi vCPU (virtual CPU) ánh xạ trực tiếp đến một lõi vật lý, điều này có thể cải thiện tính cô lập và nhất quán trong khối lượng công việc.\nChọn loại instance Amazon EC2 dùng AMD EPYC phù hợp Việc chọn loại instance Amazon EC2 dùng AMD EPYC phù hợp bắt đầu bằng việc hiểu cách ứng dụng của bạn sử dụng tài nguyên tính toán (compute), bộ nhớ, lưu trữ và mạng. Mỗi instance family được tối ưu hóa cho những đặc tính khối lượng công việc nhất định.\nKhối lượng công việc tính toán\nNhững khối lượng này liên quan tới các phép tính quy mô lớn, mô phỏng, hoặc mã hóa, và thường cần thông lượng CPU cao và hỗ trợ tập lệnh nâng cao.\nKhuyến nghị: C7a, Hpc7a, C6a, Hpc6a\nTình huống dùng: điện toán khoa học, mô hình tài chính, chuyển mã media, mã hóa, inference ML\nBig Data \u0026amp; Analytics\nỨng dụng xử lý và phân tích tập dữ liệu lớn hưởng lợi từ băng thông bộ nhớ cao và tỷ lệ tính toán‑bộ nhớ cân bằng.\nKhuyến nghị: R7a, M7a, R6a, M6a\nTình huống dùng: xử lý luồng, phân tích thời gian thực, công cụ business intelligence, caching phân tán\nKhối lượng công việc cơ sở dữ liệu\nCông việc database thường cần hiệu suất bộ nhớ ổn định và throughput I/O cao cho các hoạt động đọc/ghi.\nKhuyến nghị: R7a, M7a, R6a, M6a\nTình huống dùng: database quan hệ (MySQL, PostgreSQL), NoSQL (MongoDB, Cassandra), database trong bộ nhớ (Redis)\nWeb và máy chủ ứng dụng\nNhững ứng dụng này xử lý các tải yêu cầu biến đổi và hưởng lợi từ sự cân bằng giữa tính toán, bộ nhớ và hiệu năng mạng.\nKhuyến nghị: C7a, M7a, C6a, M6a\nTình huống dùng: máy chủ web, hệ quản lý nội dung, nền tảng e‑commerce, các điểm cuối API\nAI/ML trên CPU\nCác tác vụ ML không cần GPU — như inference hoặc tiền xử lý — có thể chạy hiệu quả trên các instance dựa CPU.\nKhuyến nghị: M7a, R7a, C7a\nTình huống dùng: inference mô hình, xử lý ngôn ngữ tự nhiên, thị giác máy tính, hệ gợi ý\nHigh Performance Computing\nNhững khối lượng công việc này cần nhiều lõi, băng thông bộ nhớ cao và mạng độ trễ thấp cho các tính toán liên kết chặt chẽ.\nKhuyến nghị: Hpc7a, Hpc6a, R7a, M7a\nTình huống dùng: động lực chất lỏng, genomics, phân tích địa chấn, mô phỏng kỹ thuật\nViệc phù hợp hóa loại instance với nhu cầu khối lượng công việc giúp cung cấp hiệu suất dự đoán được và hiệu quả chi phí. Các dịch vụ như Amazon EC2 Auto Scaling và AWS Compute Optimizer có thể hỗ trợ trong việc lựa chọn instance và ra quyết định scale liên tục.\nTối ưu hóa các instance Amazon EC2 dùng AMD EPYC Các instance EC2 dùng bộ xử lý AMD EPYC thế hệ thứ 4 vận hành với kiến trúc “chiplet modular”, như minh họa trong hình dưới đây. Mỗi bộ xử lý bao gồm nhiều Core Complex Dies (CCD), và mỗi CCD chứa một hoặc nhiều tổ hợp lõi (core complexes, gọi là CCX). Một CCX gom tối đa tám lõi vật lý, mỗi lõi có 1 MB bộ nhớ đệm L2 riêng và tám lõi đó cùng chia sẻ 32 MB bộ nhớ đệm L3. Các CCD này được kết nối với một die I/O trung tâm, chịu trách nhiệm quản lý bộ nhớ và liên kết giữa các chip.\n(Biểu đồ 1: Sơ đồ của die CPU ‘Zen 4’ với 8 lõi mỗi die)\nKiến trúc module của các bộ xử lý AMD EPYC thế hệ thứ 4 cho phép các instance như m7a.24xlarge và m7a.48xlarge hỗ trợ số lượng lõi cao — lên đến 96 lõi vật lý mỗi socket. Ví dụ:\nm7a.24xlarge cung cấp 96 lõi vật lý từ một socket đơn\nm7a.48xlarge trải rộng hai socket, cung cấp 192 lõi vật lý\nHiểu cách các kích cỡ instance của EC2 ánh xạ tới bố cục bộ xử lý vật lý có thể giúp bạn tối ưu hóa hiệu suất và tính nhất quán bộ nhớ đệm (cache). Những khối lượng công việc liên quan tới truy cập bộ nhớ chia sẻ hoặc đồng bộ hóa luồng — như HPC hoặc database trong bộ nhớ — có thể hưởng lợi khi chọn kích cỡ instance giảm thiểu giao tiếp giữa socket và tận dụng hiệu quả bộ nhớ đệm L3.\n(Biểu đồ 2: Bố cục CPU ‘EPYC Chiplet’)\nCác instance EC2 dùng AMD EPYC thế hệ thứ 4 hoạt động với SMT bị tắt. Trong cấu hình này, mỗi vCPU ánh xạ trực tiếp tới một lõi vật lý, loại bỏ chia sẻ tài nguyên như đơn vị thực thi và bộ nhớ đệm giữa các luồng “chị/em”. Thiết kế này có thể giảm nhiễu nội lõi và giúp cung cấp hiệu suất ổn định hơn cho các khối lượng công việc nhất định. Người dùng có thể cô lập luồng ở cấp lõi và quan sát độ biến thiên thấp hơn và thông lượng ổn định hơn cho các khối lượng như HPC, inference ML và database giao dịch.\nCPU optimizations Các công cụ như htop giúp xác định mẫu sử dụng CPU, trung bình tải hệ thống, và tiêu thụ tài nguyên theo tiến trình. Việc sử dụng CPU nên được đánh giá trong ngữ cảnh khối lượng công việc và yêu cầu hiệu năng. Nếu mức sử dụng liên tục đạt 100%, điều đó có thể chỉ ra rằng khối lượng công việc bị CPU-bound và chưa được cân bằng tối ưu. Trước khi thay đổi kích thước instance, bật Auto Scaling, hoặc chuyển đổi giữa các gia đình instance, cần thực hiện đánh giá các cơ hội tuning có thể cải thiện hiệu suất mà không thay đổi hạ tầng. Trung bình tải (load averages) vượt thường xuyên hơn số lượng vCPU cũng có thể là dấu hiệu bão hòa tính toán và có thể yêu cầu tối ưu tiếp.\nSử dụng bộ nhớ đệm L3 L3 cache là lớp nhớ nhanh chia sẻ được sử dụng bởi một nhóm lõi CPU. Trên EC2 dựa AMD, các lõi được tổ chức thành các slice bộ nhớ đệm L3, mỗi slice được chia sẻ bởi một tập hợp lõi trên cùng một socket. Các luồng được lập lịch trong cùng slice có thể truy cập dữ liệu chia sẻ hiệu quả hơn, giảm độ trễ bộ nhớ. Trên các instance AMD thế hệ 4 như m7a.2xlarge hoặc r7a.2xlarge, tất cả vCPU thường ánh xạ tới các lõi nằm trong cùng một slice L3, đảm bảo tính nhất quán địa phương bộ nhớ đệm. Đối với các kích cỡ lớn hơn (ví dụ m7a.8xlarge trở lên), thread pinning — gán các luồng tới lõi vật lý cụ thể — có thể giúp duy trì tính địa phương này. Thread pinning có thể giảm biến động hiệu suất trong các khối lượng với mẫu truy cập bộ nhớ chia sẻ thường xuyên.\nBạn có thể pin luồng với lệnh:\ntaskset -c 0-3 ./your_application\nVí dụ này pin ứng dụng của bạn vào các lõi CPU 0 đến 3. Để xác định lõi nào chia sẻ cùng vùng bộ nhớ đệm L3, sử dụng các công cụ như lscpu hoặc lstopo để kiểm tra topology CPU hệ thống. Gom các luồng liên quan vào các lõi cùng chia sẻ L3 cache có thể cải thiện tính nhất quán hiệu suất cho các khối lượng có truy cập bộ nhớ chia sẻ.\nTối ưu container Docker Trong môi trường container chạy trên các instance EC2 dựa AMD, điều chỉnh các thiết lập liên quan CPU có thể cải thiện tính nhất quán và hiệu quả khối lượng công việc — đặc biệt cho các ứng dụng tính toán nặng hoặc nhạy độ trễ. Mặc dù cấu hình mặc định hoạt động cho nhiều kịch bản tổng quát, một số workload có thể lợi từ việc kiểm soát rõ ràng cách phân bổ tài nguyên CPU. Theo mặc định, runtime container như Docker cho phép hệ điều hành lập lịch container trên bất kỳ lõi CPU nào sẵn có. Việc này có thể dẫn đến biến thiên hiệu suất khi container di chuyển giữa các lõi không chia sẻ cache. Để giảm biến thiên và cải thiện hiệu quả cache, container có thể được pin vào các lõi cụ thể bằng flag --cpuset-cpus.\ndocker run --cpuset-cpus=\u0026ldquo;1,3\u0026rdquo; my-container\nThiết lập này giới hạn container chỉ dùng các lõi đã chỉ định. Trong ví dụ này, lõi 1 và 3 được dùng để minh hoạ. Lựa chọn lõi thực tế nên dựa trên topology CPU để đảm bảo lập lịch hiệu quả bộ nhớ đệm. Pin container vào các lõi chia sẻ bộ nhớ đệm L3 có thể giảm overhead lập lịch và cải thiện tính nhất quán cho các workload có mẫu truy cập bộ nhớ chia sẻ.\nThiết lập governor tần số CPU Một số hệ điều hành điều chỉnh tần số CPU động để tiết kiệm điện. Thông thường điều này được kiểm soát bởi thiết lập gọi là CPU frequency governor. Mặc dù hành vi này hiệu quả cho các workload tổng quát, nó có thể gây độ trễ hoặc biến thiên hiệu suất trong môi trường nhạy với tính toán. Với các workload cần hiệu suất CPU ổn định cao — như xử lý dữ liệu thông lượng lớn, mô phỏng, hoặc ứng dụng thời gian thực — chúng tôi khuyến nghị đặt governor của CPU về performance mode. Điều này đảm bảo CPU chạy ở tần số tối đa khi chịu tải, tránh thời gian tăng tốc từ trạng thái năng lượng thấp.\nBạn có thể áp dụng thiết lập này trên các instance bare metal hoặc Amazon EC2 Dedicated Hosts bằng lệnh:\nsudo cpupower frequency-set -g performance\nTrước khi áp dụng, hãy cân nhắc benchmark hiệu suất workload với các governor khác (như ondemand hoặc schedutil) để đảm bảo rằng chế độ performance mang lại lợi ích đo được mà không đánh đổi điện năng không cần thiết.\nDùng flag compiler kiến trúc cụ thể Khi biên dịch các ứng dụng C hoặc C++ nhạy hiệu suất, các flag kiến trúc cụ thể như -march=znverX có thể mở khóa tối ưu hóa dành riêng cho AMD EPYC, bao gồm cải thiện vectorization và hiệu suất số thực. Dù điều này có lợi cho workload tính toán nặng, nó có thể giảm tính di động giữa các kiến trúc. Để cân bằng giữa hiệu suất và tính linh hoạt, cân nhắc dùng phát hiện tính năng thời chạy (runtime feature detection) và dispatching — cách nhiều thư viện tối ưu dùng để thích ứng hành vi dựa trên CPU nền tảng.\nTrước khi dùng các flag này, xác minh rằng phiên bản compiler của bạn hỗ trợ chúng và đảm bảo kiến trúc instance EC2 đích phù hợp với flag chỉ định. Ví dụ, một binary biên dịch với -march=znver4 có thể lỗi chạy với lỗi “illegal instruction” (SIGILL) nếu chạy trên các instance thế hệ trước như M5a. Bảng dưới đây mô tả các flag phù hợp và phiên bản compiler tối thiểu hỗ trợ cho mỗi thế hệ AMD EPYC:\nThế hệ AMD EPYC Flag -march Phiên bản GCC tối thiểu Phiên bản LLVM/Clang tối thiểu Thế hệ 4 (ví dụ M7a) znver4 GCC 12 Clang 15 Thế hệ 3 (ví dụ M6a) znver3 GCC 11 Clang 13 Thế hệ 2 (ví dụ M5a) znver2 GCC 9 Clang 11 Các flag sau được hỗ trợ cho GCC 11+ hoặc LLVM Clang 13+:\nCho EPYC thế hệ 4 (M7a, R7a, C7a, Hpc7a): -march=znver4\nCho EPYC thế hệ 3 (M6a, R6a, C6a): -march=znver3\nCho EPYC thế hệ 2 (M5a, R5a, C5a): -march=znver2\nKhi nào bật AVX‑512 và VNNI Các instance EC2 dùng AMD EPYC thế hệ 4 hỗ trợ các tập lệnh SIMD tiên tiến như AVX2, AVX‑512 và VNNI. Những tập lệnh này có thể cải thiện thông lượng cho các workload vector nặng như inference ML, xử lý hình ảnh hoặc mô phỏng khoa học. Tuy nhiên, những flag này là đặc trưng theo thế hệ — việc cố chạy các binary được biên dịch với AVX‑512 trên instance không hỗ trợ (ví dụ thế hệ 2 như M5a) có thể gây lỗi thời gian chạy như “illegal instruction” (SIGILL).\nKhi biên dịch mã C hoặc C++:\ngcc -mavx2 -mavx512f -O2 your_program.c -o your_program\nĐể hiểu rõ hơn tối ưu hóa nào được áp dụng, dùng:\n-ftree-vectorizer-verbose=2 -fopt-info-vec-missed\nCách này giúp xác định các vòng lặp hưởng lợi từ vectorization và những vòng lặp không. Chỉ bật các tối ưu hóa này nếu workload của bạn hưởng lợi và bạn đã xác thực tính tương thích với thế hệ instance đang dùng. Tránh áp dụng flag AVX một cách bừa bãi, vì có thể làm giảm tính di động và tăng độ phức tạp binary.\nThư viện tối ưu CPU của AMD (AMD Optimizing CPU Libraries – AOCL) Thư viện AMD Optimizing CPU Libraries (AOCL) cung cấp các thư viện toán học được tinh chỉnh hiệu năng dành riêng cho các bộ xử lý AMD EPYC. Những thư viện này bao gồm các triển khai tối ưu của các hàm hay dùng trong khoa học, kỹ thuật và workload ML. Bạn có thể liên kết ứng dụng của bạn với AOCL để sử dụng các tối ưu phần cứng mà không cần viết lại mã. AOCL gồm các thư viện cho toán vector, scalar, tạo số ngẫu nhiên, FFT, BLAS và LAPACK, trong số những cái khác.\nCấu hình AOCL Gán biến môi trường AOCL_ROOT trỏ tới thư mục cài đặt:\nexport AOCL_ROOT=/path/to/aocl\nBiên dịch ứng dụng với đường dẫn include và library tương ứng:\ngcc -I$AOCL_ROOT/include -L$AOCL_ROOT/lib -lamdlibm -lm your_program.c -o your_program\nTối ưu toán vector và scalar: bạn có thể bật các tuning vector hóa hay scalar cụ thể cho workload:\n# Tối ưu toán vector\ngcc -lamdlibm -fveclib=AMDLIBM -lm your_program.c -o your_program\n# Toán scalar nhanh hơn\ngcc -lamdlibm -fsclrlib=AMDLIBM -lamdlibmfast -lm your_program.c -o your_program\nProfiling runtime AOCL\nAOCL hỗ trợ profiling runtime, giúp các nhà phát triển xác định các phép toán nào chiếm thời gian thực thi lớn. Để bật profiling:\nexport AOCL_PROFILE=1\n./your_program\nSau khi chạy, một file báo cáo tên aocl_profile_report.txt được sinh ra. Nó cung cấp phân tích theo hàm gồm số lần gọi, thời gian thực thi và việc sử dụng luồng. Các nhà phát triển có thể dùng nó để tập trung tối ưu hóa vào các phần có ảnh hưởng cao nhất.\nKết luận Bài viết này khảo sát cách chọn các loại instance Amazon EC2 dựa AMD phù hợp với đặc điểm khối lượng công việc, và cách áp dụng các kỹ thuật điều chỉnh tập trung vào việc sử dụng CPU, định vị luồng, hiệu quả cache và tối ưu thư viện toán học. Những phương pháp này đặc biệt quan trọng với khối lượng công việc bị giới hạn bởi CPU hoặc nhạy độ trễ, nơi hiệu suất ổn định là thiết yếu.\nSẵn sàng bắt đầu? Đăng nhập AWS Management Console và khởi động các instance Amazon EC2 dùng AMD EPYC để bắt tay vào tối ưu hóa workload của bạn ngay hôm nay.\nTAGS: AMD\n"
},
{
	"uri": "http://localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]